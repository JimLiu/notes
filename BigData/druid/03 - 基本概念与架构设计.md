## 基本概念与架构设计
### 时间序列数据库 (Time-series database)
1. InfluxDB
2. Graphite
3. OpenTSDB
### 指标系统
1. 容量可控
2. Schema less
3. 数据可视化
### 分页式 OLAP 数据库
1. ES - 明细数据检索, 越来越多分析功能
2. Kylin - 预计算 + kv 存储
3. Preso - SQL on Hadoop
### druid 擅长的部分
1. 对于大部分数据查询可以做到亚秒级响应
2. 事件流实时写入与批量数据写入
3. 数据写入前预聚合，节省存储空间，提升查询效率
4. 水平扩容能力强
5. 社区活跃
### druid 短板的部分
1. 不支持 join
2. 大数据量场景下明细查询有瓶颈 （关闭 roll-up 功能）
### 是否需要使用 druid
1. 处理时间序列事件
2. 快速聚合以及探索式分析
3. 近实时响应
4. 存储量大
5. 无单点问题的数据存储
### Druid 基本概念与特性
#### 数据模型
1. 事件
    Druid 将事件分解成三种数据类型：
    - Timestamp column
    - Dimension columns 过滤与分组
    - Metric columns 多是数值列，用于聚合计算  
2. Roll-up
    数据预聚合，可以减少大量的数据存储
3. 数据存储
    - Segment 文件
       - Druid 将数据保存到 Segment 文件中，Segment 文件还可以根据时间进行 partition , Segment 文件中，会保存维度，指标，索引信息。
       - Chunk -> Segment -> Partition
       - 将行式存储转换成列式存储
    - 有三种类型的数据结构：
        - timestamp
        - 指标列： int 数组， float 数组
        - 维度列： 支持过滤与分组，使用压缩的 BitMap 索引
        
#### 数据写入

1. 实时数据写入
    a: Kafka-index-service b: realtimeNode c: tranquility 三种方式
    - KafkaIndexingService 机制对接 kafka, offset 存储在 mysql 中，依赖于 overlord 这个服务
    - 数据格式
      json, csv, tsv
2. 离线数据写入
    a: MR 高吞吐量的离线任务 b: Indexer 通过实时任务索引离线数据（用于测试）
    - 支持的文件类型 (hdfs, s3 ...)
      TextFile
    - 索引方式
      内部 Indexer (数据集 < 1G, 开发测试用)
      基于 MapReducer 任务的 Indexer

#### 数据查询
1. 查询模式
   Scatter & Gather 的模式。 在这个方面有点类似于 kylin 正在实现的真实时查询。
2. DSL 查询介绍
   HTTP/JSON 的 DSL
3. SQL 查询介绍
   HTTP/JSON 的 SQL, 0.10 版本开始支持，之前是不支持的。
4. JDBC
   不建议，比较慢。
#### 查询类型
1. Timeseries 返回时间序列
2. TopN 除时间外的一个维度列聚合
3. Group by 除时间以外的一个或者多个维度的列聚合
4. Select 查询 Druid 原始数据
5. Search 查询 维度列的值
6. Time boundary 查询一个数据源可查询数据的时间范围
7. Metadata query 元数据查询
8. Scan 查询
   0.10 之前也是社区一个插件，后续才合并到主分支里面。

### coordinator
1. leader 选举
2. 服务发现
3. 任务发布
4. 数据 发布
### 元数据存储
1. Segment 相关表
2. Rule 相关表
3. 
